#pragma kernel ReduceSum1
#pragma kernel ReduceSum2

//Reduction blocksize must be equal to or greater than 64!!!
#define REDUCTION_BLOCKSIZE 128

RWStructuredBuffer<int3> tempSum; //used to go between sums. Should equal blocksize number
StructuredBuffer<int3> inputSum;
RWStructuredBuffer<int3> result;
uint dispatchDim;

groupshared int3 sdata[REDUCTION_BLOCKSIZE];


//TL;DR
//setUint(dispatchDim =  N / REDUCTION_BLOCKSIZE / 2) -> this means only two sums are required
//dispatch(dispatchDim, sum1)
//dispatch(1, sum2)

//tid -> wthin threadgroup index
//groupIdx -> which threadgroup is running
[numthreads(REDUCTION_BLOCKSIZE, 1, 1)]
void ReduceSum1(uint tid : SV_GroupIndex, uint3 groupIdx : SV_GroupID)
{
	uint n, _;
	int steps = 0;
	inputSum.GetDimensions(n, _);

	//get the offset for where we will read
	//notice that within groups, they should have neighboring is.
	uint i = groupIdx.x * (REDUCTION_BLOCKSIZE * 2) + tid;
	uint dispatchSize = REDUCTION_BLOCKSIZE * 2 * dispatchDim;

	sdata[tid] = int3(0, 0, 0); //this data is shared within the group, so tid < REDUCTION_BLOCKSIZE

	do {
		//we read our assigned value AND one from a neighboring value.
		//This extra value is why we have a factor of 2 above
		sdata[tid] += inputSum[i] + inputSum[i + REDUCTION_BLOCKSIZE];
		i += dispatchSize; //we increment to the next set if we need to based on the size of the input array (n)
	} while (i < n);

	GroupMemoryBarrierWithGroupSync(); //wait for all threads in group to finish reading

	//based on the size of the thread groups (which is fixed at compile time)
	//we perform one extra left-hand side reduction. So tid 4, for example, will grab what tid 68 had
	//all sums are now stored between 0 and 64
	if (REDUCTION_BLOCKSIZE >= 512) { if (tid < 256) { sdata[tid] += sdata[tid + 256]; } GroupMemoryBarrierWithGroupSync(); }

	if (REDUCTION_BLOCKSIZE >= 256) { if (tid < 128) { sdata[tid] += sdata[tid + 128]; } GroupMemoryBarrierWithGroupSync(); }

	if (REDUCTION_BLOCKSIZE >= 128) { if (tid < 64) { sdata[tid] += sdata[tid + 64]; } GroupMemoryBarrierWithGroupSync(); }

	//why do the above require sync, but not those below?
	//becaue each step above requires data from the previous step

	//why do the below not require sync? Because Instructions are SIMD synchronous within a warp
	//at < 32, we are in a single warp.
	//Due to the inability to assign volatile to the groupshared memory,
	//I have to synch these. They should execute in lockstep, but they don't;
	if (tid < 32) {
		sdata[tid] += sdata[tid + 32]; //now all sums are between 0 and 32	
		GroupMemoryBarrier();
		sdata[tid] += sdata[tid + 16]; //between 0 and 16....
		GroupMemoryBarrier();
		sdata[tid] += sdata[tid + 8];
		GroupMemoryBarrier();
		sdata[tid] += sdata[tid + 4];
		GroupMemoryBarrier();
		sdata[tid] += sdata[tid + 2];
		GroupMemoryBarrier();
		sdata[tid] += sdata[tid + 1];
	}

	if (tid == 0) {
		tempSum[groupIdx.x] = sdata[0]; //finally we are done in our group and add that to output data.		
	}

}

//same as above, but requires n == groupDim and does not use two elments for summation.
[numthreads(REDUCTION_BLOCKSIZE, 1, 1)]
void ReduceSum2(uint tid : SV_GroupIndex, uint3 groupIdx : SV_GroupID)
{
	//get the offset for where we will read
	//notice that within groups, they should have neighboring is.
	uint i = groupIdx.x * REDUCTION_BLOCKSIZE + tid;


	//got rid of the extra summation term to better balance sum1/sum2
	sdata[tid] = tempSum[i]; //this data is shared within the group, so tid < REDUCTION_BLOCKSIZE

	GroupMemoryBarrierWithGroupSync(); //wait for all threads in group to finish reading

									   //based on the size of the thread groups (which is fixed at compile time)
									   //we perform one extra left-hand side reduction. So tid 4, for example, will grab what tid 68 had
									   //all sums are now stored between 0 and 64
	if (REDUCTION_BLOCKSIZE >= 512) { if (tid < 256) { sdata[tid] += sdata[tid + 256]; } GroupMemoryBarrierWithGroupSync(); }

	if (REDUCTION_BLOCKSIZE >= 256) { if (tid < 128) { sdata[tid] += sdata[tid + 128]; } GroupMemoryBarrierWithGroupSync(); }

	if (REDUCTION_BLOCKSIZE >= 128) { if (tid < 64) { sdata[tid] += sdata[tid + 64]; } GroupMemoryBarrierWithGroupSync(); }

	//why do the below not require sync? Because Instructions are SIMD synchronous within a warp
	//at < 32, we are in a single warp.
	//Due to the inability to assign volatile to the groupshared memory,
	//I have to synch these. They should execute in lockstep, but they don't;
	if (tid < 32) {
		sdata[tid] += sdata[tid + 32]; //now all sums are between 0 and 32	
		GroupMemoryBarrier();
		sdata[tid] += sdata[tid + 16]; //between 0 and 16....
		GroupMemoryBarrier();
		sdata[tid] += sdata[tid + 8];
		GroupMemoryBarrier();
		sdata[tid] += sdata[tid + 4];
		GroupMemoryBarrier();
		sdata[tid] += sdata[tid + 2];
		GroupMemoryBarrier();
		sdata[tid] += sdata[tid + 1];
	}

	if (tid == 0) {
		result[0] = sdata[0];
	}

}
